from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st
import os


st.set_page_config(
    page_title="KB HRD ì±—ë´‡",
    page_icon="ğŸ“ƒ",
)

# Path to the pre-designated file
PRE_REGISTERED_FILE_PATH = './files/hrdrule.pdf'  # Change this to your file's path

class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)

@st.cache_data(show_spinner="í•™ìŠµì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆì–´ìš”...")
def embed_file(file_path, api_key):
    with open(file_path, "rb") as file:
        file_content = file.read()

    # Process and embed the file content
    cache_dir = LocalFileStore(f"./.cache/embeddings/{os.path.basename(file_path)}")
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)  # Use the user's API key here
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)
    vectorstore = FAISS.from_documents(docs, cached_embeddings)
    retriever = vectorstore.as_retriever()
    return retriever

def save_message(message, role):
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    st.session_state["messages"].append({"message": message, "role": role})

def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)

def paint_history():
    if "messages" in st.session_state:
        for message in st.session_state["messages"]:
            send_message(
                message["message"],
                message["role"],
                save=False,
            )

def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            Answer the question using ONLY the following context. Do not learn or retain any information from these documents beyond this session. If you don't know the answer just say you don't know. DON'T make anything up.
            
            Context: {context}
            """,
        ),
        ("human", "{question}"),
    ]
)

st.title("KB HRD ì±—ë´‡")

st.markdown(
    """
ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” KBì†í•´ë³´í—˜ ì¸ì¬ê°œë°œíŒŒíŠ¸ì—ì„œ ê°œë°œí•œ "KB HRD ì±—ë´‡"ì…ë‹ˆë‹¤.

OpenAIì˜ GPT API, Streamlit, Langchain ë“±ì„ í™œìš©í•˜ì—¬ ë§Œë“¤ì–´ì¡Œìœ¼ë©°, HRD ì œë„ì§‘ì„ ì—´ì‹¬íˆ í•™ìŠµí–ˆë‹µë‹ˆë‹¤.

ê¶ê¸ˆí•˜ì‹  ì ì„ ë¬¼ì–´ë´ì£¼ì‹œë©´, í•™ìŠµí•œ ë²”ìœ„ ë‚´ì—ì„œ ì¼ëª©ìš”ì—°í•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš” ^^
"""
)

# Sidebar: User input for OpenAI API Key
with st.sidebar:
    openai_api_key = st.text_input("Enter your OpenAI API Key", type="password")

# Check if the API key is provided
if openai_api_key:
    st.session_state["openai_api_key"] = openai_api_key

    # Load the pre-registered file
    if os.path.exists(PRE_REGISTERED_FILE_PATH):
        retriever = embed_file(PRE_REGISTERED_FILE_PATH, st.session_state["openai_api_key"])
        send_message("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", "ai", save=False)
        paint_history()
        message = st.chat_input("ê¶ê¸ˆí•˜ì‹  ì ì„ ì—¬ê¸°ì— ì ì–´ì£¼ì„¸ìš”...")
        if message:
            send_message(message, "human")
            chain = (
                {
                    "context": retriever | RunnableLambda(format_docs),
                    "question": RunnablePassthrough(),
                }
                | prompt
                | ChatOpenAI(temperature=0.1, streaming=True, callbacks=[ChatCallbackHandler()], openai_api_key=st.session_state["openai_api_key"])  # Pass the user's API key
            )
            with st.chat_message("ai"):
                chain.invoke(message)
    else:
        st.error(f"The file at {PRE_REGISTERED_FILE_PATH} does not exist.")
else:
    st.error("Please enter your OpenAI API Key in the sidebar to start.")

###